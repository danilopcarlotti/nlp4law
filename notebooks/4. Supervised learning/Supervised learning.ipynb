{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "df = pd.read_csv(Path().absolute().parent / \"3. Clustering/text_class.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, str(Path().absolute().parent.parent))\n",
    "\n",
    "from src.text_vectorization import hashing_texts\n",
    "\n",
    "X = hashing_texts(df[\"text\"], 2**15)\n",
    "y = df[\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA AGUMENTATION WITH SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before data augmentation with SMOTE\n",
      "(64, 32768)\n",
      "Counter({0: 48, 1: 16})\n",
      "After data augmentation with SMOTE\n",
      "(96, 32768)\n",
      "Counter({1: 48, 0: 48})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(\"Before data augmentation with SMOTE\")\n",
    "print(X_train.shape)\n",
    "print(Counter(y_train))\n",
    "\n",
    "oversample = SMOTE()\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"After data augmentation with SMOTE\")\n",
    "print(X_train.shape)\n",
    "print(Counter(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def stacking_clf():\n",
    "    estimators = [\n",
    "        (\"Random Forest\", RandomForestClassifier(random_state=42)),\n",
    "        (\"Logistic Regression\", LogisticRegression()),\n",
    "        (\"Gradient Boosting\", GradientBoostingClassifier(random_state=42)),\n",
    "    ]\n",
    "    stacking_classifier = StackingClassifier(\n",
    "        estimators=estimators, final_estimator=LogisticRegression()\n",
    "    )\n",
    "    return stacking_classifier\n",
    "\n",
    "def predict_function(X, y, with_smote=True):\n",
    "    rows = []\n",
    "    for name, clf in [\n",
    "        (\"stacking_ensemble\", stacking_clf()),\n",
    "        (\"gradient_boosting\", GradientBoostingClassifier()),\n",
    "        (\"logistic_regression\", LogisticRegression()),\n",
    "    ]:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "        if with_smote:\n",
    "            oversample = SMOTE()\n",
    "            X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        sensitivity = tp / (fn + tp) if (fn + tp) else 0\n",
    "        specificity = tn / (tn + fp) if (tn + fp) else 0\n",
    "        precision = tp / (fp + tp) if (fp + tp) else 0\n",
    "        rows.append({\n",
    "            \"model\":name,\n",
    "            \"sensitivity\":sensitivity,\n",
    "            \"specificity\":specificity,\n",
    "            \"precision\":precision,\n",
    "            \"smote\":with_smote\n",
    "        })\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting without smote\n",
      "                 model  sensitivity  specificity  precision  smote\n",
      "0    stacking_ensemble          0.6         0.75      0.375  False\n",
      "1    gradient_boosting          0.6         0.75      0.375  False\n",
      "2  logistic_regression          0.0         1.00      0.000  False\n",
      "Predicting with smote\n",
      "                 model  sensitivity  specificity  precision  smote\n",
      "0    stacking_ensemble          1.0         0.85   0.625000   True\n",
      "1    gradient_boosting          1.0         0.80   0.555556   True\n",
      "2  logistic_regression          1.0         0.95   0.833333   True\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicting without smote\")\n",
    "df_without_smote = pd.DataFrame(predict_function(X, y, with_smote=False))\n",
    "print(df_without_smote)\n",
    "df_without_smote.to_excel(\"results_without_smote.xlsx\", index=False)\n",
    "print(\"Predicting with smote\")\n",
    "df_com_smote = pd.DataFrame(predict_function(X, y))\n",
    "print(df_com_smote)\n",
    "df_com_smote.to_excel(\"results_with_smote.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
