{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLUSTERING WITH KMEDOIDS\n",
    "\n",
    "- The objective is to find k clusters of similar documents given a certain corpus\n",
    "- The main analysis are:\n",
    " - Find the texts closest to the center of each cluster and manually read them for insight\n",
    " - Measure the density of each cluster and how far apart they are from one another\n",
    " - The distribution of texts in each class (if the texts are already classified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "df = pd.read_csv(Path().absolute().parent.parent / \"data/text_class_8k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rows = []\n",
    "for row in df.to_dict(\"records\"):\n",
    "    if re.search(r\"alienação fiduciária\", row[\"text\"], flags=re.I|re.S):\n",
    "        new_rows.append(row)\n",
    "df = pd.DataFrame(new_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, str(Path().absolute().parent.parent))\n",
    "\n",
    "from src.text_vectorization import hashing_texts\n",
    "\n",
    "X = hashing_texts(df[\"text\"], 2**14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268, 16384)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "def closest_n_index(X, n_clusters=10):\n",
    "    kmedoids = KMedoids(n_clusters=n_clusters, random_state=0).fit(X)\n",
    "    return kmedoids.medoid_indices_, kmedoids.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_centers, labels = closest_n_index(X, n_clusters=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 2, 4, 3, 1, 0, 2, 1, 4, 1, 1, 1, 1, 3, 3, 2, 1, 4, 4, 3,\n",
       "       3, 1, 0, 1, 1, 1, 3, 2, 0, 3, 2, 0, 4, 0, 0, 0, 0, 1, 4, 1, 3, 0,\n",
       "       2, 3, 1, 1, 4, 4, 4, 4, 3, 3, 3, 2, 4, 4, 0, 4, 2, 0, 2, 1, 4, 3,\n",
       "       1, 1, 4, 4, 1, 0, 0, 4, 0, 4, 4, 4, 2, 1, 1, 0, 2, 4, 4, 2, 4, 3,\n",
       "       2, 2, 2, 4, 0, 4, 3, 3, 4, 1, 0, 0, 3, 2, 4, 1, 2, 3, 3, 3, 4, 1,\n",
       "       1, 1, 1, 1, 3, 4, 1, 1, 0, 1, 4, 1, 1, 3, 1, 4, 0, 3, 1, 4, 1, 2,\n",
       "       1, 1, 2, 4, 4, 1, 2, 0, 4, 4, 2, 4, 3, 4, 1, 4, 4, 0, 2, 4, 1, 1,\n",
       "       1, 4, 0, 1, 2, 2, 3, 1, 1, 4, 2, 4, 1, 2, 0, 0, 0, 4, 3, 4, 3, 2,\n",
       "       2, 2, 2, 4, 4, 4, 4, 4, 4, 1, 4, 2, 0, 0, 0, 2, 2, 4, 4, 4, 4, 2,\n",
       "       2, 4, 1, 1, 1, 1, 3, 4, 1, 2, 4, 4, 3, 1, 1, 4, 2, 2, 4, 2, 3, 4,\n",
       "       1, 0, 0, 2, 2, 1, 1, 1, 1, 4, 1, 4, 1, 1, 2, 3, 3, 2, 0, 1, 3, 4,\n",
       "       0, 3, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 3, 3, 3, 1, 3, 1, 1,\n",
       "       1, 4, 4, 3], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts = df.iloc[indices_centers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts.to_excel(Path().absolute().parent.parent / \"data/text_class_8k_medoids.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"grupo\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score of  0.028147100620629865\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score as ss\n",
    "\n",
    "print(\"Silhouette score of \", ss(X, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_mato = (\"mato\", r\"mandado\")\n",
    "regex_deferimento_liminar = (\"liminar_deferida\", r\"( defiro|concedo).{,5}liminar\")\n",
    "regex_ato_ordinatorio = (\"ato_ordinatorio\", r\"intimada|intimação\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for row in df.to_dict(\"records\"):\n",
    "    if re.search(regex_ato_ordinatorio[1], row[\"text\"], flags=re.I|re.S) and re.search(regex_mato[1], row[\"text\"], flags=re.I|re.S):\n",
    "        y.append(1)\n",
    "    else:\n",
    "        y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 81, 4: 70, 2: 44, 3: 39, 0: 34})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_clusters = {}\n",
    "for index, item in enumerate(labels):\n",
    "    if item not in classes_clusters:\n",
    "        classes_clusters[item] = {0:0,1:0}\n",
    "    classes_clusters[item][y[index]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {0: 54, 1: 27},\n",
       " 2: {0: 41, 1: 3},\n",
       " 4: {0: 61, 1: 9},\n",
       " 3: {0: 39, 1: 0},\n",
       " 0: {0: 27, 1: 7}}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
